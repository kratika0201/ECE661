{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "###################### Making necessary library imports ###################### \n",
    "##############################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import optimize\n",
    "from skimage import feature\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "########################## Task 1  ############################################\n",
    "###############################################################################\n",
    "\n",
    "# Function to get an initial estimate of Fundamental Matrix\n",
    "def estimate_fundamental_matrix(points1,points2,n):\n",
    "\n",
    "    # declare empty A matrix of size n X 9\n",
    "    # n is the number of point correspondences\n",
    "    A_matrix =  np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        P_1 = points1[i]\n",
    "        P_2 = points2[i]\n",
    "\n",
    "        # x and y coordinates of point in the left image\n",
    "        x = P_1[0]\n",
    "        y = P_2[1]\n",
    "\n",
    "        # x and y coordinates of point in the right image\n",
    "        x_dash = P_1[0]\n",
    "        y_dash = P_2[1]\n",
    "\n",
    "        # construct the A matrix\n",
    "        A_matrix[i,:] = np.array(([x_dash*x,x_dash*y,x_dash,y_dash*x,y_dash*y,y_dash,x,y,1]))\n",
    "\n",
    "    # compute svd\n",
    "    U,S,V = np.linalg.svd(A_matrix)\n",
    "    h = V[8]\n",
    "    F = h.reshape(3,3)\n",
    "\n",
    "    # return the fundamental matrix\n",
    "    return F\n",
    "\n",
    "# Function to enforce rank constraint on Fundamental Matrix\n",
    "def condition_F(input_F):\n",
    "\n",
    "    U,S,V = np.linalg.svd(input_F)\n",
    "\n",
    "    # this step conditions the fundamental matrix\n",
    "    S[2] = 0\n",
    "    D = np.dot(np.diag(S),V)\n",
    "    F = np.dot(U,D)\n",
    "\n",
    "    # return the rank 2 fundamental matrix\n",
    "    return F\n",
    "\n",
    "# Function to estimate both epipoles from Fundamental matrix\n",
    "def estimate_epipoles(F):\n",
    "\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "\n",
    "    # left epipole\n",
    "    e = np.transpose(V[2,:])\n",
    "\n",
    "    # right epipole\n",
    "    e_dash = U[:,2]\n",
    "\n",
    "    # return both epipoles\n",
    "    return e,e_dash\n",
    "\n",
    "# Function to get left and right projection matrices in canonical configuration\n",
    "def estimate_projection_canonical(e_dash,F):\n",
    "\n",
    "    # left camera projection matrix\n",
    "    P = np.array(([1,0,0,0],[0,1,0,0],[0,0,1,0]))\n",
    "\n",
    "    # right camera projection matrix\n",
    "    P_dash = np.zeros((3,4))\n",
    "    s = np.array(([0,(-1)*e_dash[2],e_dash[1]],\n",
    "                 [e_dash[2],0,(-1)*e_dash[0]],\n",
    "                 [(-1)*e_dash[1],e_dash[0],0]))\n",
    "    M = np.dot(s,F)\n",
    "    P_dash[:,3] = e_dash\n",
    "    P_dash[0:3,0:3] = M\n",
    "\n",
    "    # return projection matrices in canonical form\n",
    "    return P,P_dash\n",
    "    \n",
    "# Function to mark points on an image given coordinates\n",
    "# Taken from HW2 and HW3 submissions\n",
    "def draw_bounding_box(image,x,y):\n",
    "    \n",
    "    # Display the image\n",
    "    # x is the list of x coordinates of the points that need to be marked\n",
    "    # y is the list of y coordinates of the points that need to be marked\n",
    "    plt.figure(figsize=(6,6))\n",
    "    fig = plt.imshow(image)\n",
    "    for i in range(len(x)):\n",
    "        plt.plot(x[i],y[i],marker='.',color=\"red\")\n",
    "        plt.text(x[i],y[i],str(i+1),horizontalalignment='right',color='white',fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # to show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Function for calculating cost function for non-linear optimization\n",
    "# Inspired/Derived from previous 2020 HW submissions\n",
    "def compute_cost_function(f,x1,x2,y1,y2,P,P_dash):\n",
    "\n",
    "    # Reshape fundamental matrix vector to a 3 X 3 matrix\n",
    "    F = f.reshape(3,3)\n",
    "\n",
    "    # compute left and right epipoles using F matrix\n",
    "    e,e_dash = estimate_epipoles(F)\n",
    "\n",
    "    # normalize left epipole\n",
    "    e = e/e[2]\n",
    "\n",
    "    # normalize right epipole\n",
    "    e_dash = e_dash/e_dash[2]\n",
    "\n",
    "    # obtain left and right projection matrices in canonical form\n",
    "    P,P_dash = estimate_projection_canonical(e_dash,F)\n",
    "\n",
    "    e = []\n",
    "    for i in range(len(x1)):\n",
    "\n",
    "        # transform 2-D points to 3-D points using projection matrices\n",
    "        D = np.zeros((4,4))\n",
    "        D[0] = x1[i]*P[2] \n",
    "        D[0] = D[0] - P[0]\n",
    "        D[1] = y1[i]*P[2] \n",
    "        D[1] = D[1] - P[1]\n",
    "        D[2] = x2[i]*P_dash[2]\n",
    "        D[2] = D[2] - P_dash[0]\n",
    "        D[3] = y2[i]*P_dash[2] \n",
    "        D[3] = D[3] - P_dash[1]\n",
    "        U,S,V = np.linalg.svd(D)\n",
    "        X = np.transpose(V[3])\n",
    "        X = X/X[3]\n",
    "\n",
    "        # project world coordinate using left camera\n",
    "        projected_coord_1 = np.dot(P,X)\n",
    "\n",
    "        # normalize in homogeneous coordinates\n",
    "        projected_coord_1 = projected_coord_1/projected_coord_1[2]\n",
    "\n",
    "        # project world coordinate using right camera\n",
    "        projected_coord_2 = np.dot(P_dash,X)\n",
    "\n",
    "        # normalize in homogeneous coordinates\n",
    "        projected_coord_2 = projected_coord_2/projected_coord_2[2]\n",
    "\n",
    "        # computer geometric error for left camera\n",
    "        # between actual pixel and projected pixel\n",
    "        points1_hom = np.array(([projected_coord_1[0],projected_coord_1[1],1]))\n",
    "        points1 = np.array(([x1[i],y1[i],1]))\n",
    "        error_img_1 = np.linalg.norm(points1 - points1_hom)\n",
    "        error_img_1 = np.square(error_img_1)\n",
    "        e.append(error_img_1)\n",
    "\n",
    "        # computer geometric error for right camera\n",
    "        # between actual pixel and projected pixel\n",
    "        points2_hom = np.array(([projected_coord_2[0],projected_coord_2[1],1]))\n",
    "        points2 = np.array(([x2[i],y2[i],1]))\n",
    "        error_img_2 = np.linalg.norm(points2 - points2_hom)\n",
    "        error_img_2 = np.square(error_img_2)\n",
    "        e.append(error_img_2)\n",
    "    overall_error = np.ravel(e)\n",
    "\n",
    "    # return total error for non-linear optimization\n",
    "    return overall_error\n",
    "\n",
    "# Function for estimating left and right homographies for rectification\n",
    "# Inspired/Derived from previous 2020 HW submissions\n",
    "def computing_homographies(H,W,P,P_dash,F,e,e_dash,x1,x2,y1,y2):\n",
    "\n",
    "    # H: height of any one of the images\n",
    "    # W: width of any one of the images\n",
    "    # P,P_dash: left and right camera projection matrices \n",
    "    # F: refined and conditioned fundamental matrix\n",
    "    # e,e_dash: left and right epipoles\n",
    "    # x1,y1: point correspondences in left image\n",
    "    # x2,y2: point correspondences in right image\n",
    "\n",
    "    # Right Image\n",
    "    # For computing H_dash, we need to compute G,R,T matrices first\n",
    "    # compute angle and other needed parameters\n",
    "    theta1 = e_dash[1] - (H/2)\n",
    "    theta2 = e_dash[0] - (W/2)\n",
    "    theta = math.atan2(theta1,-theta2)\n",
    "    f1 = np.cos(theta)*(e_dash[0] - (W/2))\n",
    "    f2 = np.sin(theta)*(e_dash[1] - (H/2))\n",
    "    f = f1 - f2\n",
    "    c = np.cos(theta) \n",
    "    s = np.sin(theta)\n",
    "\n",
    "    # computing G\n",
    "    G = np.array(([1,0,0],[0,1,0],[-1/f,0,1]))\n",
    "    # computing R\n",
    "    R = np.array(([c,-s,0],[s,c,0],[0,0,1]))\n",
    "    # compute T\n",
    "    T = np.array(([1,0,-W/2],[0,1,-H/2],[0,0,1]))\n",
    "\n",
    "    # compute right homography H_dash\n",
    "    H_dash = np.dot(R,T)\n",
    "    H_dash = np.dot(G,H_dash)\n",
    "    # normalize right homography\n",
    "    H_dash = H_dash/H_dash[2,2]\n",
    "\n",
    "    # Apply right homography to center of right image\n",
    "    center_2 = np.array([W/2,H/2,1]) \n",
    "    new_center_2 = np.dot(H_dash,center_2)\n",
    "    # Normalize\n",
    "    new_center_2 = new_center_2/new_center_2[2]\n",
    "\n",
    "    # compute right translation matrix w.r.t center\n",
    "    trans_2 = np.array(([1,0,(W/2) - new_center_2[0]],[0,1,(H/2) - new_center_2[1]],[0,0,1]))\n",
    "    H_dash_new = np.dot(trans_2,H_dash)\n",
    "    # H_dash_new is the normalized final right homography\n",
    "    H_dash_new = H_dash_new /H_dash_new [2,2]\n",
    "\n",
    "    # Left Image\n",
    "    # For computing H, we need to compute G,R,T matrices first\n",
    "    # compute angle and other needed parameters\n",
    "    theta1 = e[1] - (H/2)\n",
    "    theta2 = e[0] - (W/2)\n",
    "    theta = math.atan2(theta1,-theta2)\n",
    "    f1 = np.cos(theta)*(e[0] - (W/2))\n",
    "    f2 = np.sin(theta)*(e[1] - (H/2))\n",
    "    f = f1 - f2\n",
    "    c = np.cos(theta) \n",
    "    s = np.sin(theta)\n",
    "\n",
    "    # computing G\n",
    "    G = np.array(([1,0,0],[0,1,0],[-1/f,0,1]))\n",
    "    # computing R\n",
    "    R = np.array(([c,-s,0],[s,c,0],[0,0,1]))\n",
    "    # compute T\n",
    "    T = np.array(([1,0,-W/2],[0,1,-H/2],[0,0,1]))\n",
    "\n",
    "    # compute initial left homography H\n",
    "    H_left_init = np.dot(R,T)\n",
    "    H_left_init = np.dot(G,H_left_init)\n",
    "\n",
    "    # compute cost to minimize distance\n",
    "    A = np.zeros((len(x1),3))\n",
    "    B = np.zeros((len(x1),3))\n",
    "    for i in range(len(x1)):\n",
    "        point1 = np.array(([x1[i],y1[i],1]))\n",
    "        point2 = np.array(([x2[i],y2[i],1]))\n",
    "        trans_point_1 = np.dot(H_left_init,point1)\n",
    "        trans_point_2 = np.dot(H_dash_new,point2)\n",
    "        trans_point_1 = trans_point_1/trans_point_1[2]\n",
    "        trans_point_2 = trans_point_2/trans_point_2[2]\n",
    "        A[i,:] = trans_point_1\n",
    "        B[i,:] = trans_point_2\n",
    "\n",
    "    # using linear least squares\n",
    "    A_inv = np.linalg.pinv(A)\n",
    "    C = np.dot(A_inv,B[:,0])\n",
    "    a = C[0]; b = C[1]; c = C[2]\n",
    "    H_a = np.array(([a,b,c],[0,1,0],[0,0,1]))\n",
    "\n",
    "    # Estimate of left homography that will rectify the center of left image\n",
    "    H_left_c = np.dot(H_a,H_left_init)\n",
    "\n",
    "    # Apply left homography to center of left image\n",
    "    # compute center of left image\n",
    "    center_1 = np.array([W/2,H/2,1]) \n",
    "    new_center_1 = np.dot(H_left_c,center_1)\n",
    "\n",
    "    # normalize the rectified left image center\n",
    "    new_center_1 = new_center_1/new_center_1[2]\n",
    "\n",
    "    # compute left translation matrix w.r.t center\n",
    "    trans_1 = np.array(([1,0,(W/2) - new_center_1[0]],[0,1,(H/2) - new_center_1[1]],[0,0,1]))\n",
    "    H_new = np.dot(trans_1,H_left_c)\n",
    "    # H_new is the normalized final left homography\n",
    "    H_new = H_new / H_new[2,2]\n",
    "\n",
    "    # return both left and right homographies\n",
    "    return H_new,H_dash_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a RGB image to grayscale\n",
    "# Taken from HW8 submission\n",
    "def convert_rgb_grayscale(input_rgb):\n",
    "    \n",
    "    grayscale_image = cv2.cvtColor(input_rgb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return grayscale_image\n",
    "\n",
    "# Function to detect edges using Canny Edge Detector\n",
    "# Taken from HW8 submission\n",
    "def canny_edge_detector(input_image):\n",
    "    \n",
    "    # convert rgb to grayscale image\n",
    "    input_image = convert_rgb_grayscale(input_image)\n",
    "\n",
    "    # extract edges using Canny Edge Detector of Skimage\n",
    "    edges_image = feature.canny(input_image,sigma=3)\n",
    "\n",
    "    # plot the image with detected edges\n",
    "    plt.figure()\n",
    "    plt.imshow(edges_image,cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # return the image with edges\n",
    "    return edges_image\n",
    "\n",
    "# Function to find point correspondences after rectification\n",
    "# Inspired/Derived from previous 2020 HW submissions\n",
    "def find_correspondences(edges_image_1,edges_image_2):\n",
    "\n",
    "    correspondence_list_1 = []\n",
    "    correspondence_list_2 = []\n",
    "\n",
    "    #compute the number of rows\n",
    "    num_rows = edges_image_1.shape[0]\n",
    "    for i in range(num_rows):\n",
    "\n",
    "        # check where pixels are non-zero i.e. pixels detected by canny edge detector\n",
    "        non_zero_pos = np.where(edges_image_1[i] > 0 )\n",
    "\n",
    "        # detect the row coordinate of that non-zero pixel\n",
    "        for j in non_zero_pos[0]:\n",
    "            start_column = j\n",
    "            end_column = j + 30\n",
    "\n",
    "            # search within same row for the right image in a range of columns\n",
    "            cols_region = edges_image_2[i,start_column:end_column ]\n",
    "            if np.size(np.where(cols_region>0)[0]) != 0:\n",
    "                k = j+ np.where(cols_region>0)[0][0]\n",
    "                edges_image_2[i,k] = 0\n",
    "\n",
    "                # save point correspondences of both rectified images \n",
    "                correspondence_list_1.append([j,i])\n",
    "                correspondence_list_2.append([k,i])\n",
    "    return correspondence_list_1,correspondence_list_2\n",
    "\n",
    "# Functions to use SSD metric to find correspondence matches \n",
    "# Borrowed from HW4 submission \n",
    "def compute_ssd(img1,img2,corners_for_image_1,corners_for_image_2):\n",
    "\n",
    "    '''\n",
    "    Input  - img1                : Grayscale first image\n",
    "           - img2                : Grayscale second image\n",
    "           - corners_for_image_1 : Detected corners using Harris for Image 1\n",
    "           - corners_for_image_2 : Detected corners using Harris for Image 2\n",
    "    Output - coordinate_array_1_top: Selected corners in first image after SSD \n",
    "           - coordinate_array_2_top: Selected corners in second image after SSD \n",
    "    '''\n",
    "\n",
    "    #Size of window chosen m = 6\n",
    "    m = 6\n",
    "\n",
    "    value_list = []\n",
    "    coordinate_list_1 = []\n",
    "    coordinate_list_2 = []\n",
    "\n",
    "    # Normalize grayscale images 1 and 2\n",
    "    img_1_norm = img1/np.max(img1)\n",
    "    img_2_norm = img2/np.max(img2)\n",
    "\n",
    "    # extract a (m+1) X (m+1) patch around the corners in both images and save them to two arrays\n",
    "    # apply SSD formula to both arrays\n",
    "    # Repeat for all corners and choose top 200 corner pairs which give least SSD\n",
    "    for i in range(len(corners_for_image_1)):\n",
    "        for j in range(len(corners_for_image_2)):\n",
    "\n",
    "            point_1 = corners_for_image_1[i]\n",
    "            point_2 = corners_for_image_2[j]\n",
    "\n",
    "            array_1 = np.zeros((m+1,m+1))\n",
    "            array_2 = np.zeros((m+1,m+1))\n",
    "\n",
    "            if point_1[0] - m > 0 :\n",
    "                if point_1[0] < img1.shape[0] - m - 1:\n",
    "                    array_1 = img_1_norm[point_1[0] - int(m/2):point_1[0]+int((m+2)/2), point_1[1] - int(m/2):point_1[1]+int((m+2)/2)]\n",
    "            if point_2[0] - m > 0 :\n",
    "                if point_2[0] < img2.shape[0] - m - 1:\n",
    "                    array_2 = img_2_norm[point_2[0] - int(m/2):point_2[0]+int((m+2)/2), point_2[1] - int(m/2):point_2[1]+int((m+2)/2)]\n",
    "            \n",
    "            # applying SSD criterion\n",
    "            if array_1.shape == array_2.shape:\n",
    "                value = np.sum(np.square(np.abs(array_1-array_2)))\n",
    "                value_list.append(value)\n",
    "                coordinate_list_1.append(point_1)\n",
    "                coordinate_list_2.append(point_2)\n",
    "\n",
    "    value_array = np.array(value_list)\n",
    "\n",
    "    # get all unique SSD distances\n",
    "    value_array,value_array_index = np.unique(value_array,return_index=True,return_inverse=False,return_counts=False, axis=None)\n",
    "    coordinate_array_1 = np.array(coordinate_list_1)[value_array_index]\n",
    "    coordinate_array_2 = np.array(coordinate_list_2)[value_array_index]\n",
    "\n",
    "    # sort the distances in ascending order\n",
    "    value_sorted_indices = np.argsort(value_array)\n",
    "\n",
    "    # choose top 200 minimum distances and select those corners\n",
    "    value_top_100 =  value_sorted_indices[0:200]\n",
    "    coordinate_array_1_top =  coordinate_array_1[value_top_100]\n",
    "    coordinate_array_2_top =  coordinate_array_2[value_top_100]\n",
    "    return coordinate_array_1_top,coordinate_array_2_top\n",
    "            \n",
    "# Function to draw point correspondences given matches and two images\n",
    "# Borrowed from HW4 submission \n",
    "def draw_matches_harris(corners_1,corners_2,img1,img2,name):\n",
    "\n",
    "    # stack the image pair together\n",
    "    overall_image = np.hstack((img1,img2))\n",
    "\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.axis('off')\n",
    "    plt.title('{}'.format(name))\n",
    "    for i in range(min(len(corners_1),len(corners_2))):\n",
    "        # for random line color generation\n",
    "        r = random.random()\n",
    "        b = random.random()\n",
    "        g = random.random()\n",
    "        color = (r, g, b)\n",
    "        plt.plot([corners_1[i][0],(corners_2[i][0]+img1.shape[1])],[corners_1[i][1],corners_2[i][1]],color=color,linewidth=0.5)\n",
    "    plt.imshow(overall_image)\n",
    "\n",
    "# Function to do 3-D projective reconstruction from rectified images\n",
    "# Inspired/Derived from previous 2020 HW submissions\n",
    "def projective_reconstruction(x1,x2,y1,y2,P,P_dash):\n",
    "\n",
    "    # P,P_dash: left and right camera projection matrices \n",
    "    # x1,y1: point correspondences in left image\n",
    "    # x2,y2: point correspondences in right image\n",
    "    n = 4\n",
    "    three_D_vec_array = []\n",
    "    for i in range(len(x1)):\n",
    "        D = np.zeros((n,n))\n",
    "        D[0] = x1[i]*P[2] \n",
    "        D[0] = D[0] - P[0]\n",
    "        D[1] = y1[i]*P[2] \n",
    "        D[1] = D[1] - P[1]\n",
    "        D[2] = x2[i]*P_dash[2]\n",
    "        D[2] = D[2] - P_dash[0]\n",
    "        D[3] = y2[i]*P_dash[2] \n",
    "        D[3] = D[3] - P_dash[1]\n",
    "\n",
    "        # to compute world coordinate using one pair of point correspondences\n",
    "        U,S,V = np.linalg.svd(D)\n",
    "        X = np.transpose(V[3])\n",
    "        X = X/X[3]\n",
    "        three_D_vec_array.append(X)\n",
    "    three_D_vec_array = np.array(three_D_vec_array)\n",
    "\n",
    "    # return all world points\n",
    "    return three_D_vec_array\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "########################## Main functions of Task 1  ##########################\n",
    "###############################################################################\n",
    "\n",
    "# Displaying own stereo images\n",
    "img1 = cv2.imread ('Task1Images/task_2_1_img7.png')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.imread ('Task1Images/task_2_1_img8.png')\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Manually picked left image point correspondences for F and homography estimation\n",
    "x1_orig = [491,480,820,197,466,200,790,64]\n",
    "y1_orig = [394,701,484,104,895,776,624,506]\n",
    "\n",
    "# Show corresponding points on respective stereo images\n",
    "draw_bounding_box(img1,x1_orig,y1_orig)\n",
    "\n",
    "# Manually picked right image point correspondences for F and homography estimation\n",
    "x2_orig = [471,440,794,165,431,169,761,31]\n",
    "y2_orig = [400,710,485,118,904,790,622,524]\n",
    "\n",
    "# Show corresponding points on respective stereo images\n",
    "draw_bounding_box(img2,x2_orig,y2_orig)\n",
    "\n",
    "# Normalize corresponding points by mean\n",
    "# Inspired/Derived from previous 2020 HW submissions\n",
    "x_mean_img_1 = sum(x1_orig)/8\n",
    "y_mean_img_1 = sum(y1_orig)/8\n",
    "x_mean_img_2 = sum(x2_orig)/8\n",
    "y_mean_img_2 = sum(y2_orig)/8\n",
    "# computer errors w.r.t mean\n",
    "error1 = np.array(x1_orig) - x_mean_img_1\n",
    "error2 = np.array(x2_orig) - x_mean_img_2\n",
    "error3 = np.array(y1_orig) - y_mean_img_1\n",
    "error4 = np.array(y2_orig) - y_mean_img_2\n",
    "error_img_1 = np.square(error1) + np.square(error3)\n",
    "error_img_1 = np.sqrt(error_img_1)\n",
    "error_img_2 = np.square(error2) + np.square(error4)\n",
    "error_img_2 = np.sqrt(error_img_2)\n",
    "c_img_1 = math.sqrt(2)/np.mean(error_img_1)\n",
    "c_img_2 = math.sqrt(2)/np.mean(error_img_2)\n",
    "r_img_1 = c_img_1*x_mean_img_1\n",
    "r_img_2 = c_img_2*x_mean_img_2\n",
    "\n",
    "# Translational matrices for normalization \n",
    "T1 = np.array([[c_img_1,0,-r_img_1], \n",
    "               [0,c_img_1,-r_img_1],\n",
    "               [0,0,1]])\n",
    "T2 = np.array([[c_img_2,0,-r_img_2], \n",
    "               [0,c_img_2,-r_img_2], \n",
    "               [0,0,1]])\n",
    "\n",
    "# Transform all corresponding points using translational matrices for both images\n",
    "trans_pts_img_1_x = []\n",
    "trans_pts_img_1_y = []\n",
    "trans_pts_img_2_x = []\n",
    "trans_pts_img_2_y = []\n",
    "for i in range(len(x1_orig)):\n",
    "     trans_pts_img_1 = np.dot(T1,np.transpose(np.array(([x1_orig[i],y1_orig[i],1]))))\n",
    "     trans_pts_img_2 = np.dot(T2,np.transpose(np.array(([x2_orig[i],y2_orig[i],1]))))\n",
    "     trans_pts_img_1 = trans_pts_img_1/trans_pts_img_1[2]\n",
    "     trans_pts_img_2 = trans_pts_img_2/trans_pts_img_2[2]\n",
    "     trans_pts_img_1_x.append(trans_pts_img_1[0])\n",
    "     trans_pts_img_1_y.append(trans_pts_img_1[1])\n",
    "     trans_pts_img_2_x.append(trans_pts_img_2[0])\n",
    "     trans_pts_img_2_y.append(trans_pts_img_2[1])\n",
    "\n",
    "# These are the normalized transformed corresponding points\n",
    "x1 = trans_pts_img_1_x\n",
    "y1 = trans_pts_img_1_y\n",
    "x2 = trans_pts_img_2_x\n",
    "y2 = trans_pts_img_2_y\n",
    "p1 = (x1[0],y1[0]); p2 = (x1[1],y1[1]); p3 = (x1[2],y1[2]); p4 = (x1[3],y1[3]); p5 = (x1[4],y1[4])\n",
    "p6 = (x1[5],y1[5]); p7 = (x1[6],y1[6]); p8 = (x1[7],y1[7])\n",
    "q1 = (x2[0],y2[0]); q2 = (x2[1],y2[1]); q3 = (x2[2],y2[2]); q4 = (x2[3],y2[3]); q5 = (x2[4],y2[4])\n",
    "q6 = (x2[5],y2[5]); q7 = (x2[6],y2[6]); q8 = (x2[7],y2[7])\n",
    "points1 = [p1,p2,p3,p4,p5,p6,p7,p8]\n",
    "points2 = [q1,q2,q3,q4,q5,q6,q7,q8]\n",
    "\n",
    "# Compute fundamental matrix using normalized points\n",
    "input_F = estimate_fundamental_matrix(points1,points2,8)\n",
    "\n",
    "# condition F to constraint its rank to 2\n",
    "F = condition_F(input_F)\n",
    "\n",
    "# Apply normalization transformations\n",
    "F = np.dot(np.dot(np.transpose(T2),F),T1)\n",
    "\n",
    "# Normalize fundamental matrix \n",
    "F = F/F[2,2] \n",
    "\n",
    "# Estimate left and right epipoles, normalize and compute projection matrices\n",
    "# in canonical form\n",
    "e,e_dash = estimate_epipoles(F)\n",
    "e = e/e[2]\n",
    "e_dash = e_dash/e_dash[2]\n",
    "P,P_dash = estimate_projection_canonical(e_dash,F)\n",
    "\n",
    "# convert 3 X 3 Fundamental matrix to a 9 element vector for NL optimization\n",
    "f = np.ravel(F)\n",
    "\n",
    "# Apply non-linear optimization to refine F\n",
    "F_refined = optimize.least_squares(compute_cost_function,f,args=[x1_orig,x2_orig,y1_orig,y2_orig,P,P_dash],method='lm')\n",
    "\n",
    "# Extract only array component of output\n",
    "F_refined = F_refined.x\n",
    "\n",
    "# Reshape vector to form 3 X 3 matrix\n",
    "F_refined = F_refined.reshape(3,3)\n",
    "F_refined = F_refined/F_refined[2,2]\n",
    "print(\"F_refined\",F_refined)\n",
    "\n",
    "# Estimate left and right epipoles from refined F\n",
    "e,e_dash = estimate_epipoles(F_refined)\n",
    "e = e/e[2]\n",
    "e_dash = e_dash/e_dash[2]\n",
    "\n",
    "# Estimate left and right projection matrices from refined F\n",
    "P,P_dash = estimate_projection_canonical(e_dash,F_refined)\n",
    "\n",
    "# Compute both homographies for rectification\n",
    "H,H_dash = computing_homographies(img1.shape[0],img1.shape[1],P,P_dash,F,e,e_dash,x1,x2,y1,y2)\n",
    "print(\"H\",H)\n",
    "print(\"H_dash\",H_dash)\n",
    "\n",
    "# Apply homographies to both original images to rectify them\n",
    "plt.figure()\n",
    "rect_img_1 = cv2.warpPerspective(img1,H,(img1.shape[0],img1.shape[1]))\n",
    "plt.imshow(rect_img_1)\n",
    "rect_img_2 = cv2.warpPerspective(img2,H_dash,(img2.shape[0],img2.shape[1]))\n",
    "plt.figure()\n",
    "plt.imshow(rect_img_2)\n",
    "cv2.imwrite(\"task_2_recitified_img7_new.png\",rect_img_1)\n",
    "cv2.imwrite(\"task_2_recitified_img8_new.png\",rect_img_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rectified images \n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(rect_img_1)\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(rect_img_2)\n",
    "plt.axis('off')\n",
    "\n",
    "# Detect interest points using Canny Edge Detector\n",
    "edges_image_1 = canny_edge_detector(rect_img_1)\n",
    "edges_image_2 = canny_edge_detector(rect_img_2)\n",
    "\n",
    "# Find point correspondences, select best ones using SSD and plot correspondences\n",
    "corrs1,corrs2 = find_correspondences(edges_image_1,edges_image_2)\n",
    "\n",
    "# Plot only 100 point correspondences\n",
    "index = np.random.choice(len(corrs1),100,replace=False)  \n",
    "corrs1 = np.array(corrs1)\n",
    "corrs1 = corrs1[index] \n",
    "corrs2 = np.array(corrs2)\n",
    "corrs2 = corrs2[index]\n",
    "\n",
    "# Plot point correspondences\n",
    "draw_matches_harris(corrs1,corrs2,rect_img_1,rect_img_2,'Corresponding points after rectification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually selected points on rectified images for 3D projective reconstruction\n",
    "x1_orig = [96,463,829,558,73,400,770,430]\n",
    "y1_orig = [404,697,567,407,580,885,688,482]\n",
    "x2_orig = [58,418,809,531,42,363,754,397]\n",
    "y2_orig = [406,691,565,407,580,884,690,484]\n",
    "\n",
    "# plot these selected points on rectified images\n",
    "draw_bounding_box(rect_img_1,x1_orig,y1_orig)\n",
    "draw_bounding_box(rect_img_2,x2_orig,y2_orig)\n",
    "\n",
    "# Normalize corresponding points by mean\n",
    "# Inspired/Derived from previous 2020 HW submissions\n",
    "x_mean_img_1 = sum(x1_orig)/8\n",
    "y_mean_img_1 = sum(y1_orig)/8\n",
    "x_mean_img_2 = sum(x2_orig)/8\n",
    "y_mean_img_2 = sum(y2_orig)/8\n",
    "# computer errors w.r.t mean\n",
    "error1 = np.array(x1_orig) - x_mean_img_1\n",
    "error2 = np.array(x2_orig) - x_mean_img_2\n",
    "error3 = np.array(y1_orig) - y_mean_img_1\n",
    "error4 = np.array(y2_orig) - y_mean_img_2\n",
    "error_img_1 = np.square(error1) + np.square(error3)\n",
    "error_img_1 = np.sqrt(error_img_1)\n",
    "error_img_2 = np.square(error2) + np.square(error4)\n",
    "error_img_2 = np.sqrt(error_img_2)\n",
    "c_img_1 = math.sqrt(2)/np.mean(error_img_1)\n",
    "c_img_2 = math.sqrt(2)/np.mean(error_img_2)\n",
    "r_img_1 = c_img_1*x_mean_img_1\n",
    "r_img_2 = c_img_2*x_mean_img_2\n",
    "\n",
    "# Translational matrices for normalization \n",
    "T1 = np.array([[c_img_1,0,-r_img_1], \n",
    "               [0,c_img_1,-r_img_1],\n",
    "               [0,0,1]])\n",
    "T2 = np.array([[c_img_2,0,-r_img_2], \n",
    "               [0,c_img_2,-r_img_2], \n",
    "               [0,0,1]])\n",
    "\n",
    "# Transform all corresponding points using translational matrices for both images\n",
    "trans_pts_img_1_x = []\n",
    "trans_pts_img_1_y = []\n",
    "trans_pts_img_2_x = []\n",
    "trans_pts_img_2_y = []\n",
    "for i in range(len(x1_orig)):\n",
    "     trans_pts_img_1 = np.dot(T1,np.transpose(np.array(([x1_orig[i],y1_orig[i],1]))))\n",
    "     trans_pts_img_2 = np.dot(T2,np.transpose(np.array(([x2_orig[i],y2_orig[i],1]))))\n",
    "     trans_pts_img_1 = trans_pts_img_1/trans_pts_img_1[2]\n",
    "     trans_pts_img_2 = trans_pts_img_2/trans_pts_img_2[2]\n",
    "     trans_pts_img_1_x.append(trans_pts_img_1[0])\n",
    "     trans_pts_img_1_y.append(trans_pts_img_1[1])\n",
    "     trans_pts_img_2_x.append(trans_pts_img_2[0])\n",
    "     trans_pts_img_2_y.append(trans_pts_img_2[1])\n",
    "\n",
    "# These are the normalized transformed corresponding points\n",
    "x1 = trans_pts_img_1_x\n",
    "y1 = trans_pts_img_1_y\n",
    "x2 = trans_pts_img_2_x\n",
    "y2 = trans_pts_img_2_y\n",
    "p1 = (x1[0],y1[0]); p2 = (x1[1],y1[1]); p3 = (x1[2],y1[2]); p4 = (x1[3],y1[3]); p5 = (x1[4],y1[4])\n",
    "p6 = (x1[5],y1[5]); p7 = (x1[6],y1[6]); p8 = (x1[7],y1[7])\n",
    "q1 = (x2[0],y2[0]); q2 = (x2[1],y2[1]); q3 = (x2[2],y2[2]); q4 = (x2[3],y2[3]); q5 = (x2[4],y2[4])\n",
    "q6 = (x2[5],y2[5]); q7 = (x2[6],y2[6]); q8 = (x2[7],y2[7])\n",
    "points1 = [p1,p2,p3,p4,p5,p6,p7,p8]\n",
    "points2 = [q1,q2,q3,q4,q5,q6,q7,q8]\n",
    "\n",
    "# Compute fundamental matrix using normalized points\n",
    "input_F = estimate_fundamental_matrix(points1,points2,8)\n",
    "\n",
    "# condition F to constraint its rank to 2\n",
    "F = condition_F(input_F)\n",
    "\n",
    "# Apply normalization transformations\n",
    "F = np.dot(np.dot(np.transpose(T2),F),T1)\n",
    "\n",
    "# Normalize fundamental matrix \n",
    "F = F/F[2,2] \n",
    "\n",
    "# Estimate left and right epipoles, normalize and compute projection matrices\n",
    "# in canonical form\n",
    "e,e_dash = estimate_epipoles(F)\n",
    "e = e/e[2]\n",
    "e_dash = e_dash/e_dash[2]\n",
    "P,P_dash = estimate_projection_canonical(e_dash,F)\n",
    "\n",
    "# convert 3 X 3 Fundamental matrix to a 9 element vector for NL optimization\n",
    "f = np.ravel(F)\n",
    "\n",
    "# Apply non-linear optimization to refine F\n",
    "F_refined = optimize.least_squares(compute_cost_function,f,args=[x1_orig,x2_orig,y1_orig,y2_orig,P,P_dash],method='lm')\n",
    "\n",
    "# Extract only array component of output\n",
    "F_refined = F_refined.x\n",
    "\n",
    "# Reshape vector to form 3 X 3 matrix\n",
    "F_refined = F_refined.reshape(3,3)\n",
    "F_refined = F_refined/F_refined[2,2]\n",
    "print(\"F_refined\",F_refined)\n",
    "\n",
    "# Estimate left and right epipoles from refined F\n",
    "e,e_dash = estimate_epipoles(F_refined)\n",
    "e = e/e[2]\n",
    "e_dash = e_dash/e_dash[2]\n",
    "\n",
    "# Estimate left and right projection matrices from refined F\n",
    "P,P_dash = estimate_projection_canonical(e_dash,F_refined)\n",
    "\n",
    "# Compute all 3-D world points\n",
    "t = projective_reconstruction(x1_orig,y1_orig,x2_orig,y2_orig,P,P_dash )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point list is used to draw lines between points\n",
    "point_list = [(0,1),(1,2),(2,3),(0,3),(0,4),(1,5),(2,6),(3,7),(0,4),(1,5),(2,6),(6,7),(4,7),(4,5),(5,6)]\n",
    "\n",
    "# point correspondences used for 3D reconstruction\n",
    "x1_orig = [491,480,820,392,466,200,790,64]\n",
    "y1_orig = [394,701,484,501,895,776,624,506]\n",
    "x2_orig = [471,440,794,360,431,169,761,31]\n",
    "y2_orig = [400,710,485,510,904,790,622,524]\n",
    "\n",
    "# code to plot show 3-D reconstruction and point correspondences of rectified images\n",
    "fig = plt.figure(figsize=(35,35))\n",
    "ax = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "x = t[:,0]\n",
    "y = t[:,1]\n",
    "z = t[:,2]\n",
    "ax.scatter(x,y,z,s=70)\n",
    "ax.text(t[0][0],t[0][1],t[0][2], \"1\", color='red',size = 20)\n",
    "ax.text(t[1][0],t[1][1],t[1][2], \"2\", color='red',size = 20)\n",
    "ax.text(t[2][0],t[2][1],t[2][2], \"3\", color='red',size = 20)\n",
    "ax.text(t[3][0],t[3][1],t[3][2], \"4\", color='red',size = 20)\n",
    "ax.text(t[4][0],t[4][1],t[4][2], \"5\", color='red',size = 20)\n",
    "ax.text(t[5][0],t[5][1],t[5][2], \"6\", color='red',size = 20)\n",
    "ax.text(t[6][0],t[6][1],t[6][2], \"7\", color='red',size = 20)\n",
    "ax.text(t[7][0],t[7][1],t[7][2], \"8\", color='red',size = 20)\n",
    "ax.view_init(250,150)\n",
    "# code to draw lines between recontructed points\n",
    "for i in point_list:\n",
    "    x = i[0]\n",
    "    y = i[1]\n",
    "    ax.plot([t[x][0],t[y][0]],[t[x][1],t[y][1]],[t[x][2],t[y][2]])\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.axis('off')\n",
    "ax.imshow(rect_img_1)\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.axis('off')\n",
    "ax.imshow(rect_img_2)\n",
    "\n",
    "# code to plot different views of 3-D reconstruction\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1,projection='3d')\n",
    "x = t[:,0]\n",
    "y = t[:,1]\n",
    "z = t[:,2]\n",
    "ax.scatter(x,y,z,s=70)\n",
    "ax.text(t[0][0],t[0][1],t[0][2], \"1\", color='red',size = 20)\n",
    "ax.text(t[1][0],t[1][1],t[1][2], \"2\", color='red',size = 20)\n",
    "ax.text(t[2][0],t[2][1],t[2][2], \"3\", color='red',size = 20)\n",
    "ax.text(t[3][0],t[3][1],t[3][2], \"4\", color='red',size = 20)\n",
    "ax.text(t[4][0],t[4][1],t[4][2], \"5\", color='red',size = 20)\n",
    "ax.text(t[5][0],t[5][1],t[5][2], \"6\", color='red',size = 20)\n",
    "ax.text(t[6][0],t[6][1],t[6][2], \"7\", color='red',size = 20)\n",
    "ax.text(t[7][0],t[7][1],t[7][2], \"8\", color='red',size = 20)\n",
    "ax.view_init(250,50)\n",
    "# code to draw lines between recontructed points\n",
    "for i in point_list:\n",
    "    x = i[0]\n",
    "    y = i[1]\n",
    "    ax.plot([t[x][0],t[y][0]],[t[x][1],t[y][1]],[t[x][2],t[y][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# ########################## Task 3  ############################################\n",
    "# ###############################################################################\n",
    "\n",
    "def census_transform (left_img,right_img,M,d_max) :\n",
    "    disparity_map = np.zeros((left_img.shape[0],left_img.shape[1]))\n",
    "    for i in range ( d_max + int(M/2),left_img.shape[0]-int(M/2)-d_max) :\n",
    "        for j in range (left_img.shape[1]-int(M/2)-1-d_max,d_max + int(M/2)-1,-1) :\n",
    "            a = []\n",
    "            left_image_window = left_img[i-int(M/2):i+1+int(M/2),j-int(M/2):j+1+int(M/2)]\n",
    "            L_array = left_image_window > left_img[i,j]\n",
    "            left_bit_vec = np.ravel (L_array.astype(int))\n",
    "            for d in range (0,d_max+1) :\n",
    "                right_image_window = right_img [i-int(M/2):i+1+int(M/2),j-d-int(M/2):j-d+1+int(M/2)]\n",
    "                R_array = right_image_window > right_img [i,j-d]\n",
    "                right_bit_vec = np.ravel(R_array.astype(int))\n",
    "                result_bit_array = np.logical_xor(left_bit_vec,right_bit_vec)\n",
    "                unique, counts = np.unique(result_bit_array,return_counts=True)\n",
    "                counter = dict(zip(unique, counts))\n",
    "                if 1 in counter :\n",
    "                    a.append(counter[1])\n",
    "                else : \n",
    "                    a.append(0)\n",
    "            disparity_map[i,j] = np . argmin (a)\n",
    "    disparity_map = np.uint8(disparity_map)\n",
    "    disparity_map_scaled = disparity_map / np.max(disparity_map)\n",
    "    disparity_map_scaled = np.uint8(disparity_map_scaled*255)\n",
    "    return disparity_map,disparity_map_scaled\n",
    "\n",
    "def compute_accuracy_dmap(gt_d_map,computed_d_map):\n",
    "\n",
    "    comp_dmap = np.int16(computed_d_map)\n",
    "    gt_dmap = np.int16(gt_d_map)\n",
    "    error = np.uint8(abs(comp_dmap-gt_d_map))\n",
    "    valid_mask = 255 * (error <= 2)\n",
    "    valid_mask = np.uint8(valid_mask)\n",
    "    pos = np.bitwise_and(computed_d_map,valid_mask)\n",
    "    non_zero = np.count_nonzero(computed_d_map)\n",
    "    acc = np.count_nonzero(pos)/non_zero\n",
    "    for i in range(pos.shape[0]):\n",
    "        for j in range(pos.shape[1]):\n",
    "            if pos[i,j] !=0:\n",
    "                pos[i,j] = 255\n",
    "    return acc,pos\n",
    "\n",
    "left_img = cv2.imread ('Task3Images/im2.png')\n",
    "left_img = cv2.cvtColor(left_img,cv2.COLOR_BGR2GRAY)\n",
    "right_img = cv2.imread ('Task3Images/im6.png')\n",
    "right_img = cv2.cvtColor(right_img,cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(left_img,cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Left stereo image\")\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(right_img,cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Right stereo image\")\n",
    "\n",
    "left_gt_img = cv2.imread ('Task3Images/disp2.png')\n",
    "left_gt_img = cv2.cvtColor(left_gt_img,cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(left_gt_img,cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Ground truth Disparity Map in grayscale\")\n",
    "left_gt_img = np.float32(left_gt_img)\n",
    "left_gt_img = left_gt_img/4\n",
    "left_gt_img = np.uint8(left_gt_img)\n",
    "\n",
    "d_out_win_30_d_52,d_out_win_30_d_52_scaled = census_transform(left_img,right_img,30,52)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(d_out_win_30_d_52_scaled,cmap=\"gray\")\n",
    "plt.title(\"Computed Disparity Map in grayscale for Window 30 d_max = 52\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "acc,valid_mask = compute_accuracy_dmap(left_gt_img,d_out_win_30_d_52)\n",
    "print(\"Accuracy\",acc)\n",
    "plt.figure()\n",
    "plt.imshow(valid_mask,cmap=\"gray\")\n",
    "plt.title(\"Binary error mask for Window 30 d_max = 52\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "d_out_win_11_d_52,d_out_win_11_d_52_scaled = census_transform(left_img,right_img,11,52)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(d_out_win_11_d_52_scaled,cmap=\"gray\")\n",
    "plt.title(\"Computed Disparity Map in grayscale for Window 11 d_max = 52\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "acc,valid_mask = compute_accuracy_dmap(left_gt_img,d_out_win_11_d_52)\n",
    "print(\"Accuracy\",acc)\n",
    "plt.figure()\n",
    "plt.imshow(valid_mask,cmap=\"gray\")\n",
    "plt.title(\"Binary error mask for Window 11 d_max = 52\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "d_out_win_49_d_52,d_out_win_49_d_52_scaled = census_transform(left_img,right_img,49,52)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(d_out_win_49_d_52_scaled,cmap=\"gray\")\n",
    "plt.title(\"Computed Disparity Map in grayscale for Window 49 d_max = 52\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "acc,valid_mask = compute_accuracy_dmap(left_gt_img,d_out_win_49_d_52)\n",
    "print(\"Accuracy\",acc)\n",
    "plt.figure()\n",
    "plt.imshow(valid_mask,cmap=\"gray\")\n",
    "plt.title(\"Binary error mask for Window 49 d_max = 52\")\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('ece661')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edb67ac57688b5469b94ed8173318dd2b110258b9903757cef999237f863a18c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
